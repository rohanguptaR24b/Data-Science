# -*- coding: utf-8 -*-
"""knn algorithm for predicting underwieght  or normal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J38237jCj-H0o2hkyHFOCzl9R0s8_zt6
"""

# Import necessary libraries
import numpy as np
from sklearn.neighbors import KNeighborsClassifier

# Training data: Weights, Heights, and their corresponding classes
X = np.array([[51, 167], [62, 182], [69, 176], [64, 173], [65, 172], [56, 174], [55, 169], [57, 173]])
y = np.array(['Underweight', 'Normal', 'Normal', 'Normal', 'Normal', 'Underweight', 'Underweight', 'Normal'])

# Define the KNN model (k=3)
knn = KNeighborsClassifier(n_neighbors=3)

# Train the model
knn.fit(X, y)

# Predict the class for a new data point: 57 kg, 170 cm
new_data = np.array([[57, 170]])
prediction = knn.predict(new_data)

# Output the prediction
print(f'The class for the new data point (57 kg, 170 cm) is: {prediction[0]}')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

df = pd.read_excel("/content/knn.data.xlsx")
print(df)
X  = df[["weight(x)","height(y)"]]
Y = df["class"].values

# training and testing
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)

# kNN
knn = KNeighborsClassifier(n_neighbors = 3)

knn.fit(X_train,Y_train)

new = np.array([57,170])
Y_pred =  knn.predict([new])
print(Y_pred)

import pandas as pd
import numpy as np
new = pd.read_excel("/content/fruit classification dataset2.xlsx .xlsx")
print(new)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
new['size']= le.fit_transform(new['size'])
#new['type']= le.fit_transform(new['type'])
x = new[['weight','color intensity','size']].values
y = new['type'].values
#print(x)
#print(y)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)

knn.fit(x_train, y_train)

new = np.array([[140,7,1]])
y_pred = knn.predict(new)
print(y_pred)



"""import pandas as pd
df = pd.read_csv("/content/Iris.csv")
print(df.head)
x=df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]
y=df['Species']
print(x,y)
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=0)
print(x_train)
print(y_test)
print(y_train)
print(y_test)

# import the class
from sklearn.linear_model import LogisticRegression

# instantine the model(using  the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(x_train,y_train) # 75% data for analysis

import the metrics class
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test,y_pred)
print(cnf_matrix)

# import required modules
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

class_names= [0,1]
fig,ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks,class_names)
plt.yticks(tick_marks,class_names)
print
# create headmap
sns.heatmap(pd.DataFrame(cnf_matrix),annot=True,cmap="Greens",fmt="d",annot_kws={"size":10})
ax.xaxis.set_label_position("bottom")
plt.tight_layout()
plt.title("confusion matrix", y=1.4)
plt.xlabel('actual label')
plt.xlabel('predicated labels')
# plt.show

print("accuracy of the model:",metrics.accuracy_score(y_test,y_pred))
print("precision of the model:",metrics.precision_score(y_test,y_pred))




"""